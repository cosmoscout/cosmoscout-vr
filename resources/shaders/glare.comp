////////////////////////////////////////////////////////////////////////////////////////////////////
//                               This file is part of CosmoScout VR                               //
////////////////////////////////////////////////////////////////////////////////////////////////////

// SPDX-FileCopyrightText: German Aerospace Center (DLR) <cosmoscout@dlr.de>
// SPDX-License-Identifier: MIT

layout(local_size_x = 16, local_size_y = 16) in;

#if NUM_MULTISAMPLES > 0
layout(binding = 0) uniform sampler2DMS uInHDRBuffer;
#else
layout(binding = 0) uniform sampler2D uInHDRBuffer;
#endif

layout(binding = 1) uniform sampler2D uInGlareMipMap;

#ifdef ENABLE_32BIT_GLARE
layout(rgba32f, binding = 1) readonly uniform image2D uInGlare;
layout(rgba32f, binding = 2) writeonly uniform image2D uOutGlare;
#else
layout(rgba16f, binding = 1) readonly uniform image2D uInGlare;
layout(rgba16f, binding = 2) writeonly uniform image2D uOutGlare;
#endif

uniform int   uPass;
uniform int   uLevel;
uniform float uMaxLuminance;
uniform mat4  uMatP;
uniform mat4  uMatInvP;

const float PI = 3.14159265359;

// Makes four texture look-ups in the input HDRBuffer at the four pixels corresponding to
// the pixel position in the base layer of the output mipmap pyramid.
// For performance reasons, we only use one sample for multisample inputs.
vec3 sampleHDRBuffer(ivec2 pos) {
  ivec2 posTimesTwo = pos << 1;

#if NUM_MULTISAMPLES > 0
  vec3 col = texelFetch(uInHDRBuffer, ivec2(posTimesTwo + ivec2(0, 0)), 0).rgb +
             texelFetch(uInHDRBuffer, ivec2(posTimesTwo + ivec2(1, 0)), 0).rgb +
             texelFetch(uInHDRBuffer, ivec2(posTimesTwo + ivec2(0, 1)), 0).rgb +
             texelFetch(uInHDRBuffer, ivec2(posTimesTwo + ivec2(1, 1)), 0).rgb;
  return col * 0.25 / uMaxLuminance * 65500;
#else
  ivec2 size = textureSize(uInHDRBuffer, 0);
  return texture(uInHDRBuffer, vec2(posTimesTwo + 1.0) / size).rgb / uMaxLuminance * 65500;
#endif
}

// Calls the method above four times in order to allow for bilinear interpolation. This is
// required for floating point positions and results in sixteen texture look-ups.
vec3 sampleHDRBuffer(vec2 pos) {
  ivec2 ipos = ivec2(pos);
  vec3  tl   = sampleHDRBuffer(ipos);
  vec3  tr   = sampleHDRBuffer(ipos + ivec2(1, 0));
  vec3  bl   = sampleHDRBuffer(ipos + ivec2(0, 1));
  vec3  br   = sampleHDRBuffer(ipos + ivec2(1, 1));
  vec2  f    = fract(pos);
  vec3  tA   = mix(tl, tr, f.x);
  vec3  tB   = mix(bl, br, f.x);
  return mix(tA, tB, f.y);
}

// Makes four texture look-ups in the input layer of the glare mipmap at the four pixels
// corresponding to the pixel position in the current layer of the mipmap pyramid.
vec3 sampleHigherLevel(ivec2 pos) {
  ivec2 posTimesTwo = pos << 1;
  int   inputLevel  = uPass == 0 ? max(0, uLevel - 1) : uLevel;
  ivec2 size        = textureSize(uInGlareMipMap, inputLevel);
  return textureLod(uInGlareMipMap, (posTimesTwo + 1.0) / vec2(size), inputLevel).rgb;
}

// Calls the method above four times in order to allow for bilinear interpolation. This is
// required for floating point positions and results in sixteen texture look-ups.
vec3 sampleHigherLevel(vec2 pos) {
  ivec2 ipos = ivec2(pos);
  vec3  tl   = sampleHigherLevel(ipos);
  vec3  tr   = sampleHigherLevel(ipos + ivec2(1, 0));
  vec3  bl   = sampleHigherLevel(ipos + ivec2(0, 1));
  vec3  br   = sampleHigherLevel(ipos + ivec2(1, 1));
  vec2  f    = fract(pos);
  vec3  tA   = mix(tl, tr, f.x);
  vec3  tB   = mix(bl, br, f.x);
  return mix(tA, tB, f.y);
}

// Makes just one texture look-ups in the input layer of the glare mipmap at the given
// pixel position.
vec3 sampleSameLevel(ivec2 pos) {
  return texelFetch(uInGlareMipMap, pos, uLevel).rgb;
}

// Calls the method above four times in order to allow for bilinear interpolation. This is
// required for floating point positions and results in four texture look-ups.
vec3 sampleSameLevel(vec2 pos) {
  ivec2 size = textureSize(uInGlareMipMap, uLevel);
  return textureLod(uInGlareMipMap, (pos + 0.5) / vec2(size), uLevel).rgb;
}

// Rotates the given vector around a given axis.
// Based on comment from http://www.neilmendoza.com/glsl-rotation-about-an-arbitrary-axis/
vec3 rotate(vec3 v, vec3 axis, float angle) {
  return mix(dot(axis, v) * axis, v, cos(angle)) + cross(axis, v) * sin(angle);
}

// Evalutes the normal distribution function for the given value.
float getGauss(float sigma, float value) {
  return 1.0 / (sigma * sqrt(2 * PI)) * exp(-0.5 * pow(value / sigma, 2));
}

void main() {

  ivec2 pixelPos   = ivec2(gl_GlobalInvocationID.xy);
  ivec2 outputSize = imageSize(uOutGlare);

  // Discard any threads outside the output layer.
  if (pixelPos.x >= outputSize.x || pixelPos.y >= outputSize.y) {
    return;
  }

  // Take an odd number of samples to make sure that we sample the center value.
  const float samples = 2 * (GLARE_QUALITY + 1) + 1;

  // These values will contain the accumulated glare values.
  vec3  glare       = vec3(0);
  float totalWeight = 0;

  // The first glare variant computes a symmetrical gaussian blur in screen space. It is separated
  // into a vertical and horizontal component which are computed in different passes.
  // If uPass == 0, horizontal blurring happens, if uPass == 1, vertical blurring happens.
  // This is not perspectively correct but very fast.

#ifdef GLAREMODE_SYMMETRIC_GAUSS
  for (float i = 0; i < samples; ++i) {
    float offset = i - floor(samples / 2);
    float weight = getGauss(1, offset);
    totalWeight += weight;

    // If we are writing to level zero, we have to sample the input HDR buffer. For all
    // successive levels we sample the previous level in the first passes and the same level
    // in the second passes.
    if (uPass == 0 && uLevel == 0) {
      glare += sampleHDRBuffer(pixelPos + ivec2(offset, 0)) * weight;
    } else if (uPass == 0) {
      glare += sampleHigherLevel(pixelPos + ivec2(offset, 0)) * weight;
    } else {
      glare += sampleSameLevel(pixelPos + ivec2(0, offset)) * weight;
    }
  }
#endif

  // The second variant computes an asymmetric perspectively correct gaussian decomposed into two
  // components which can be roughly described as radial and circular. A naive implementation with
  // a strictly circular and a strictly radial component suffers from undefined behavior close to
  // the focal point (usually in the middle of the screen) resulting in weird glow patterns in
  // this area:
  //
  //             Primary Component            Secondary (orthogonal) Component
  //
  //                  \  |  /                              / --- \
    //                 --  X  --                            |   O   |
  //                  /  |  \                              \ --- /
  //                   radial                             circular
  //
  //
  // Therefore the implementation below uses two components like the following:
  //
  //                  \  |  /                               / -- \
    //                  |  |  |                              -- -- --
  //                  /  |  \                               \ -- /
  //            vertical / radial                  horizontal / circular

#ifdef GLAREMODE_ASYMMETRIC_GAUSS

  // Reproject the current pixel position to view space.
  vec2 posClipSpace = 2.0 * vec2(gl_GlobalInvocationID.xy) / vec2(outputSize) - 1.0;
  vec4 posViewSpace = uMatInvP * vec4(posClipSpace, 0.0, 1.0);

  // The primary component depicted above is a mixture between a vertical rotation and a radial
  // rotation. A vertical rotation would require this axis:
  vec3 rotAxisVertical = cross(posViewSpace.xyz, vec3(1, 0, 0));
  rotAxisVertical      = cross(posViewSpace.xyz, rotAxisVertical);

  // A radial rotation would be around this axis:
  vec3 rotAxisRadial = cross(posViewSpace.xyz, vec3(0, 0, -1));
  if (posViewSpace.y < 0) {
    rotAxisRadial = -rotAxisRadial;
  }

  // We mix those two axes with a factor which depends on the vertical position of our
  // pixel on the screen. The magic factor of two determines how fast we change from one to
  // another and is not very sensitive. A value of five would result in very similar images.
  float alpha   = clamp(2 * abs(posViewSpace.y / length(posViewSpace.xyz)), 0, 1);
  vec3  rotAxis = mix(rotAxisVertical, rotAxisRadial, alpha);

  // The primary passes use the axis computed above, the secondary passes use an
  // orthogonal rotation axis.
  if (uPass == 0) {
    rotAxis = normalize(rotAxis);
  } else {
    rotAxis = normalize(cross(rotAxis, posViewSpace.xyz));
  }

  // The angle covered by the gauss kernel increases quadratically with the mipmap level.
  const float totalAngle = pow(2, uLevel) * PI / 180.0;

  // Rotate the view vector to the current pixel several times around the rotation axis
  // in order to sample the vicinity.
  for (float i = 0; i < samples; ++i) {
    float angle  = totalAngle * i / (samples - 1) - totalAngle * 0.5;
    float sigma  = totalAngle / MAX_LEVELS;
    float weight = getGauss(sigma, angle);

    // Compute the rotated sample position in screen space.
    vec4 pos = uMatP * vec4(rotate(posViewSpace.xyz, rotAxis, angle), 1.0);
    pos /= pos.w;

    // Convert to texture space.
    vec2 samplePos = (0.5 * pos.xy + 0.5) * outputSize;

    // If we are writing to level zero, we have to sample the input HDR buffer. For all
    // successive levels we sample the previous level in the first passes and the same level
    // in the second passes.
    if (uPass == 0 && uLevel == 0) {
      glare += sampleHDRBuffer(samplePos) * weight;
    } else if (uPass == 0) {
      glare += sampleHigherLevel(samplePos) * weight;
    } else {
      glare += sampleSameLevel(samplePos) * weight;
    }

    totalWeight += weight;
  }
#endif

  // Make sure that we do not add energy.
  glare /= totalWeight;

  // Finally store the glare value in the output layer of the glare mipmap.
  imageStore(uOutGlare, pixelPos, vec4(glare, 0.0));
}